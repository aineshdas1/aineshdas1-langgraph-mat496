{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:09.179403Z",
     "start_time": "2025-10-26T21:26:06.708436Z"
    }
   },
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:09.188340Z",
     "start_time": "2025-10-26T21:26:09.182237Z"
    }
   },
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGSMITH_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:10.019896Z",
     "start_time": "2025-10-26T21:26:09.199652Z"
    }
   },
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 34
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:10.833161Z",
     "start_time": "2025-10-26T21:26:10.030193Z"
    }
   },
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content='Hello Lance! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 11, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_65564d8ba5', 'id': 'chatcmpl-CV2XaC0vv21x8qOGy9XrBWxu6ChgJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--1486a4ec-425a-4d8c-bc0d-ac83b29fadeb-0', usage_metadata={'input_tokens': 11, 'output_tokens': 10, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:11.594636Z",
     "start_time": "2025-10-26T21:26:10.877866Z"
    }
   },
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hi Lance! How's it going? What can I do for you today?\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:12.524265Z",
     "start_time": "2025-10-26T21:26:11.609389Z"
    }
   },
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hello Lance! How can I assist you today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:18.331185Z",
     "start_time": "2025-10-26T21:26:12.524265Z"
    }
   },
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:25.194120Z",
     "start_time": "2025-10-26T21:26:18.331185Z"
    }
   },
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' professional', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' American', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' football', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' based', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Bay', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Area', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' compete', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' League', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='NFL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' club', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' league', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='N', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='FC', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' division', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' founded', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='6', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' charter', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' All', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='-Amer', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ica', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='AA', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='FC', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' joined', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' when', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' leagues', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' merged', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Key', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Points', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' about', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='St', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='adium', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' play', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' home', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' games', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' at', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Levi', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Santa', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Clara', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' California', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' which', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' they', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' occupied', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' since', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Before', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' they', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' played', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' at', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Cand', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='lestick', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Park', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='Team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Colors', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=\" team's\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' colors', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' red', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' gold', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' white', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='Masc', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ot', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=\"'\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' mascot', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' S', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ourd', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ough', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Sam', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='Champ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ionship', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' five', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' titles', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='X', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='VI', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' XIX', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='III', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='IV', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='IX', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='),', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' successful', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' period', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' being', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='198', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' early', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='199', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' also', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' numerous', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' division', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' titles', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' conference', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' championships', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='Not', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='able', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Players', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' had', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Hall', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Fame', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Joe', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Montana', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Jerry', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Rice', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Steve', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Young', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Ronnie', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' L', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ott', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Charles', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Haley', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' among', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' others', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Jerry', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Rice', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' often', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' considered', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' one', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' greatest', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' wide', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' receivers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='Co', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='aching', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Management', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' had', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' notable', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' head', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' coaches', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Bill', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Walsh', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' who', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' credited', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' popular', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='izing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Coast', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' offense', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' As', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' my', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' last', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' update', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Kyle', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Shan', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ahan', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' head', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' coach', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' having', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' taken', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' position', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='7', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='R', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ival', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' rival', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' notably', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Dallas', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Cowboys', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Los', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Angeles', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Rams', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Seattle', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Seahawks', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' These', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' rival', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' fueled', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' competitive', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' playoff', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' match', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ups', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' divis', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ional', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' contests', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='Recent', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Performance', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' recent', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' experienced', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' both', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' highs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' lows', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' reached', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' season', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' but', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' lost', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Kansas', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' City', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' Chiefs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' working', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' maintain', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' competitiveness', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' NFC', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' rich', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' passionate', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' fan', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' base', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' significant', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' contributions', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' development', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content=' popularity', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'service_tier': 'default', 'model_provider': 'openai'}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9', chunk_position='last')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9', usage_metadata={'input_tokens': 16, 'output_tokens': 471, 'total_tokens': 487, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--cf1ef040-5e15-4998-afc3-94100c8c9cb9', chunk_position='last')}\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:30.270403Z",
     "start_time": "2025-10-26T21:26:25.207206Z"
    }
   },
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| San| Francisco| |49|ers| are| a| professional| American| football| team| based| in| the| San| Francisco| Bay| Area|.| They| compete| in| the| National| Football| League| (|NFL|)| as| a| member| of| the| league|'s| National| Football| Conference| (|N|FC|)| West| division|.| The| team| was| founded| in| |194|6| as| a| charter| member| of| the| All|-Amer|ica| Football| Conference| (|AA|FC|)| and| joined| the| NFL| in| |194|9| when| the| leagues| merged|.\n",
      "\n",
      "|###| Key| Points|:\n",
      "\n",
      "|-| **|St|adium|**|:| The| |49|ers| play| their| home| games| at| Levi|'s| Stadium| in| Santa| Clara|,| California|,| which| they| moved| to| in| |201|4|.| Before| that|,| they| played| at| Cand|lestick| Park| in| San| Francisco|.\n",
      "\n",
      "|-| **|Team| Colors|**|:| The| team's| colors| are| red|,| gold|,| and| white|.\n",
      "\n",
      "|-| **|Masc|ot|**|:| The| |49|ers|'| mascot| is| S|ourd|ough| Sam|.\n",
      "\n",
      "|-| **|Champ|ionship|s|**|:| The| |49|ers| have| won| five| Super| Bowl| titles| (|X|VI|,| XIX|,| XX|III|,| XX|IV|,| and| XX|IX|),| with| their| most| successful| period| being| the| |198|0|s| and| early| |199|0|s|.| They| have| also| won| numerous| division| titles| and| conference| championships|.\n",
      "\n",
      "|-| **|Not|able| Players|**|:| The| team| has| had| several| Hall| of| Fame| players|,| including| Joe| Montana|,| Jerry| Rice|,| Steve| Young|,| Ronnie| L|ott|,| and| Charles| Haley|,| among| others|.\n",
      "\n",
      "|-| **|Co|aching| and| Management|**|:| The| team| has| been| led| by| several| notable| coaches|,| including| Bill| Walsh|,| who| is| credited| with| popular|izing| the| \"|West| Coast| Off|ense|.\"| As| of| the| latest| season|,| the| head| coach| is| Kyle| Shan|ahan|.\n",
      "\n",
      "|-| **|R|ival|ries|**|:| The| |49|ers| have| notable| rival|ries| with| teams| such| as| the| Dallas| Cowboys|,| Los| Angeles| Rams|,| and| Seattle| Seahawks|.\n",
      "\n",
      "|-| **|Ownership|**|:| The| team| is| owned| by| the| York| family|,| with| Jed| York| serving| as| the| CEO|.\n",
      "\n",
      "|The| |49|ers| have| a| rich| history| and| are| known| for| their| passionate| fan| base|.| They| have| been| competitive| in| various| eras| and| continue| to| be| a| prominent| team| in| the| NFL|.||||"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "**⚠️ DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:30.280639Z",
     "start_time": "2025-10-26T21:26:30.270403Z"
    }
   },
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "079c2ad6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:30.700665Z",
     "start_time": "2025-10-26T21:26:30.281136Z"
    }
   },
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:44.156479Z",
     "start_time": "2025-10-26T21:26:30.700665Z"
    }
   },
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '019a226a-6a3c-73c9-87e7-e0853b161920', 'attempt': 1})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5b2aff32-08b8-4fc2-a46e-ab2db7dc0b8d'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5b2aff32-08b8-4fc2-a46e-ab2db7dc0b8d'}, {'content': '', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CV2Y6bf80xrh5NXp4K9M9MlcWYUDz', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'lc_run--91cbe46c-6f19-41e8-830b-00fb7d90f0fe-0', 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_ZxeFmTUBUfX0D4NcTzJ7HuWR', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5b2aff32-08b8-4fc2-a46e-ab2db7dc0b8d'}, {'content': '', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CV2Y6bf80xrh5NXp4K9M9MlcWYUDz', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'lc_run--91cbe46c-6f19-41e8-830b-00fb7d90f0fe-0', 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_ZxeFmTUBUfX0D4NcTzJ7HuWR', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '2b14baea-d389-4a3d-bbaa-805e1bdb0145', 'tool_call_id': 'call_ZxeFmTUBUfX0D4NcTzJ7HuWR', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5b2aff32-08b8-4fc2-a46e-ab2db7dc0b8d'}, {'content': '', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CV2Y6bf80xrh5NXp4K9M9MlcWYUDz', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'lc_run--91cbe46c-6f19-41e8-830b-00fb7d90f0fe-0', 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_ZxeFmTUBUfX0D4NcTzJ7HuWR', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '2b14baea-d389-4a3d-bbaa-805e1bdb0145', 'tool_call_id': 'call_ZxeFmTUBUfX0D4NcTzJ7HuWR', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 14, 'prompt_tokens': 159, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CV2Y7QDIomK9SQjgxZSXdWxCXoV2K', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'lc_run--2e807551-f5e7-4d77-aba3-33020caafb0d-0', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 159, 'output_tokens': 14, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}]})\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:46.311185Z",
     "start_time": "2025-10-26T21:26:44.156479Z"
    }
   },
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={} response_metadata={} id='99fad351-81a4-4554-8e70-a97a4bdfb7e6'\n",
      "=========================\n",
      "content='' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_65564d8ba5', 'id': 'chatcmpl-CV2Y9LDP2rwqN1ZmXlm7eZUUiS5Hp', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--f3b3c3dd-cd32-4f2e-b04c-513d8dc47007-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_sygsccGNfHoXnCpiIOD8YMz2', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' name='multiply' id='4ebaecaa-d8a1-427b-adc1-b1fad892a1a8' tool_call_id='call_sygsccGNfHoXnCpiIOD8YMz2'\n",
      "=========================\n",
      "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 159, 'output_tokens': 14, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 159, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CV2Y9ancG7L1QPMrzEEdyBlWtBWHL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--efee8e2b-c9c1-44c4-aeac-93da9687e4b0-0'\n",
      "=========================\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:48.993443Z",
     "start_time": "2025-10-26T21:26:46.315015Z"
    }
   },
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:26:51.383503Z",
     "start_time": "2025-10-26T21:26:49.103620Z"
    }
   },
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 019a226a-b22c-7646-92b7-575b234990d1\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_I14NGgJprJJ4n8gmBqutsCHS, Function: multiply, Arguments: {}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_I14NGgJprJJ4n8gmBqutsCHS, Function: multiply, Arguments: {}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_I14NGgJprJJ4n8gmBqutsCHS, Function: multiply, Arguments: {}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_I14NGgJprJJ4n8gmBqutsCHS, Function: multiply, Arguments: {}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_I14NGgJprJJ4n8gmBqutsCHS, Function: multiply, Arguments: {'a': 2}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_I14NGgJprJJ4n8gmBqutsCHS, Function: multiply, Arguments: {'a': 2}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_I14NGgJprJJ4n8gmBqutsCHS, Function: multiply, Arguments: {'a': 2}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_I14NGgJprJJ4n8gmBqutsCHS, Function: multiply, Arguments: {'a': 2}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_I14NGgJprJJ4n8gmBqutsCHS, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_I14NGgJprJJ4n8gmBqutsCHS, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_I14NGgJprJJ4n8gmBqutsCHS, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_I14NGgJprJJ4n8gmBqutsCHS, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_I14NGgJprJJ4n8gmBqutsCHS, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying \n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and \n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is \n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - N/A\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:27:09.594317Z",
     "start_time": "2025-10-26T21:26:51.383503Z"
    }
   },
   "source": [
    "# --- Imports ---\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage\n",
    "import time\n",
    "\n",
    "# --- Chat model setup ---\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", streaming=True)\n",
    "\n",
    "# --- Node that streams responses and can be interrupted ---\n",
    "def streaming_node(state: MessagesState):\n",
    "    print(\"Streaming started...\")\n",
    "    for chunk in llm.stream(state[\"messages\"]):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "        time.sleep(0.2)  # simulate live streaming\n",
    "    print(\"\\nStreaming finished.\")\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# --- Graph setup ---\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"streaming_node\", streaming_node)\n",
    "builder.add_edge(START, \"streaming_node\")\n",
    "builder.add_edge(\"streaming_node\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# --- Test run ---\n",
    "graph.invoke({\"messages\": [HumanMessage(content=\"Explain what AI agents do in simple words.\")]} )\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming started...\n",
      "AI agents are programs or systems designed to perform tasks automatically. They can analyze information, make decisions, and take actions to achieve specific goals. For example, an AI agent in a virtual assistant can understand voice commands and respond by providing information or carrying out tasks like setting reminders. Essentially, AI agents try to mimic human decision-making to complete tasks more efficiently.\n",
      "Streaming finished.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Explain what AI agents do in simple words.', additional_kwargs={}, response_metadata={}, id='4e2bb274-2ec1-4b94-bb9b-e015d64aa167'),\n",
       "  AIMessage(content=\"AI agents are like virtual helpers or robots that can perform tasks or make decisions on their own. They take in information from their surroundings, think about it, and then respond or act based on what they've learned. For example, a virtual assistant on your phone is an AI agent that can help you set reminders or answer questions by understanding your voice commands. Essentially, AI agents are designed to understand, learn, and interact with the world around them to help people with various tasks.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'service_tier': 'default', 'model_provider': 'openai'}, id='lc_run--f88fed80-d0a4-4b67-aa09-eff71340c72f', usage_metadata={'input_tokens': 16, 'output_tokens': 95, 'total_tokens': 111, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
